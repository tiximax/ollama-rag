# Copy to .env and adjust values for your environment.
# Do NOT commit real secrets.

# --- Core connectivity ---
# Local Ollama server
OLLAMA_BASE_URL=http://localhost:11434

# Default models
LLM_MODEL=llama3.1:8b
EMBED_MODEL=nomic-embed-text

# Provider selection for generation (embeddings always use Ollama)
# Allowed: ollama | openai
PROVIDER=ollama

# --- OpenAI (only required if PROVIDER=openai) ---
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_CONNECT_TIMEOUT=5
OPENAI_READ_TIMEOUT=180
OPENAI_MAX_RETRIES=3
OPENAI_RETRY_BACKOFF=0.6

# --- Ollama networking & performance tuning ---
OLLAMA_CONNECT_TIMEOUT=5
OLLAMA_READ_TIMEOUT=180
OLLAMA_MAX_RETRIES=3
OLLAMA_RETRY_BACKOFF=0.6
# Performance knobs (optional)
# 0 = CPU-only; tune threads/ctx to limit CPU usage during dev
OLLAMA_NUM_GPU=0
OLLAMA_NUM_THREAD=2
OLLAMA_NUM_CTX=1024

# --- RAG chunking ---
CHUNK_SIZE=800
CHUNK_OVERLAP=120

# --- Chroma persistence (multi-DB root) ---
# If set, engine will default to this root and DB_NAME below
PERSIST_ROOT=data/kb
DB_NAME=default
# Alternatively, set a single DB folder via PERSIST_DIR (e.g., data/chroma)
# PERSIST_DIR=

# --- ONNXRuntime threads (for reranker) ---
ORT_INTRA_OP_THREADS=1
ORT_INTER_OP_THREADS=1

# --- Experiment logger redaction (optional) ---
# Comma-separated keys to redact in logs (default: query)
EXP_LOG_REDACT=query
# "mask" (replace with [REDACTED]) or "hash" (sha256 prefix)
EXP_LOG_REDACT_STYLE=mask
