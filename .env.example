# Copy to .env and adjust values for your environment.
# Do NOT commit real secrets.

# --- Core connectivity ---
# Local Ollama server
OLLAMA_BASE_URL=http://localhost:11434

# Default models
LLM_MODEL=llama3.1:8b
EMBED_MODEL=nomic-embed-text

# Provider selection for generation (embeddings always use Ollama)
# Allowed: ollama | openai
PROVIDER=ollama

# --- OpenAI (only required if PROVIDER=openai) ---
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_CONNECT_TIMEOUT=5
OPENAI_READ_TIMEOUT=180
OPENAI_MAX_RETRIES=3
OPENAI_RETRY_BACKOFF=0.6

# --- Ollama networking & performance tuning ---
OLLAMA_CONNECT_TIMEOUT=5
OLLAMA_READ_TIMEOUT=180
OLLAMA_MAX_RETRIES=3
OLLAMA_RETRY_BACKOFF=0.6
# Performance knobs (optional)
# 0 = CPU-only; tune threads/ctx to limit CPU usage during dev
OLLAMA_NUM_GPU=0
OLLAMA_NUM_THREAD=2
OLLAMA_NUM_CTX=1024

# --- CORS & Security ---
# Comma-separated allowed origins for CORS (empty = same-origin only)
ALLOW_ORIGINS=
# Enable HSTS header (only behind HTTPS)
HSTS_ENABLE=0

# --- Rate limiting (optional) ---
RATE_LIMIT_ENABLED=0
RATE_LIMIT_WINDOW_SEC=60
RATE_LIMIT_MAX_REQ=60
RATE_LIMIT_PATHS=/api/query,/api/stream_query,/api/multihop_query,/api/stream_multihop_query,/api/upload

# --- Upload limits (bytes) ---
MAX_UPLOAD_BYTES=10000000
MAX_UPLOAD_FILES=5
MAX_UPLOAD_TOTAL_BYTES=30000000

# --- RAG chunking ---
CHUNK_SIZE=800
CHUNK_OVERLAP=120

# --- Chroma persistence (multi-DB root) ---
# If set, engine will default to this root and DB_NAME below
PERSIST_ROOT=data/kb
DB_NAME=default
# Alternatively, set a single DB folder via PERSIST_DIR (e.g., data/chroma)
# PERSIST_DIR=

# --- ONNXRuntime threads (for reranker) ---
ORT_INTRA_OP_THREADS=1
ORT_INTER_OP_THREADS=1

# --- Experiment logger redaction (optional) ---
# Comma-separated keys to redact in logs (default: query)
EXP_LOG_REDACT=query
# "mask" (replace with [REDACTED]) or "hash" (sha256 prefix)
EXP_LOG_REDACT_STYLE=mask
