"""
üî• Load Testing Master File - Sprint 3 Day 1
============================================

M·ª•c ƒë√≠ch: Stress-test h·ªá th·ªëng RAG v·ªõi Ollama, validate metrics th·ª±c chi·∫øn!

Features:
- Realistic user behavior simulation (query, chat, RAG retrieval)
- Multiple load patterns (normal, spike, stress)
- Live Prometheus metrics integration
- Circuit breaker & connection pool validation

Vibe: Testing nh∆∞ m·ªôt rockstar! üé∏
"""

import json
import random
import time

from locust import HttpUser, TaskSet, between, task

# ============================================================================
# üéØ Configuration - T√πy ch·ªânh theo nhu c·∫ßu stress test
# ============================================================================


class LoadTestConfig:
    """Configuration ·ªïn ƒë·ªãnh cho load tests nh∆∞ kim c∆∞∆°ng! üíé"""

    # Endpoints to test - RAG API
    RAG_QUERY_ENDPOINT = "/api/query"
    RAG_STREAM_ENDPOINT = "/api/stream_query"
    CHAT_ENDPOINT = "/api/chats"
    METRICS_ENDPOINT = "/metrics"
    HEALTH_ENDPOINT = "/health"
    CACHE_STATS_ENDPOINT = "/api/cache-stats"

    # Test data - Realistic queries
    SAMPLE_QUERIES = [
        "What is machine learning?",
        "Explain neural networks",
        "How does RAG work?",
        "Tell me about transformers",
        "What is semantic search?",
        "Explain vector databases",
        "How to optimize LLM inference?",
        "What is prompt engineering?",
        "Describe attention mechanism",
        "What are embeddings?",
    ]

    # Chat conversation templates
    CHAT_TEMPLATES = [
        {"role": "user", "content": "Hello! Can you help me understand {topic}?"},
        {"role": "assistant", "content": "Of course! I'd be happy to explain {topic}."},
        {"role": "user", "content": "Can you give me an example?"},
    ]

    # Model to use for testing
    TEST_MODEL = "llama2"  # Thay ƒë·ªïi theo model b·∫°n c√≥

    # Request timeouts (seconds)
    GENERATE_TIMEOUT = 30
    CHAT_TIMEOUT = 30
    METRICS_TIMEOUT = 5


# ============================================================================
# üé≠ User Behaviors - M√¥ ph·ªèng h√†nh vi ng∆∞·ªùi d√πng th·ª±c t·∫ø
# ============================================================================


class OllamaUserBehavior(TaskSet):
    """
    H√†nh vi user chu·∫©n ch·ªânh: query ‚Üí check metrics ‚Üí chat

    M√¥ ph·ªèng workflow th·ª±c t·∫ø c·ªßa user t∆∞∆°ng t√°c v·ªõi RAG system!
    """

    def on_start(self):
        """
        Kh·ªüi t·∫°o khi user b·∫Øt ƒë·∫ßu session.
        Nh∆∞ l√≠nh canh, setup m·ªçi th·ª© tr∆∞·ªõc khi v√†o tr·∫≠n! üö™
        """
        self.user_id = f"user_{random.randint(1000, 9999)}"
        self.session_start = time.time()
        print(f"üöÄ User {self.user_id} started session")

    @task(5)
    def rag_query(self):
        """
        Task ch√≠nh: RAG query v·ªõi retrieval (weight=5)

        ƒê√¢y l√† task ph·ªï bi·∫øn nh·∫•t, chi·∫øm 50% traffic!
        """
        query = random.choice(LoadTestConfig.SAMPLE_QUERIES)

        payload = {
            "query": query,
            "n_results": 3,  # Retrieve top 3 docs
            "rerank": False,  # Skip reranking for faster testing
        }

        with self.client.post(
            LoadTestConfig.RAG_QUERY_ENDPOINT,
            json=payload,
            timeout=LoadTestConfig.GENERATE_TIMEOUT,
            catch_response=True,
            name="RAG Query",
        ) as response:
            if response.status_code == 200:
                try:
                    data = response.json()
                    # Validate response c√≥ ƒë√∫ng format kh√¥ng
                    if "answer" in data:
                        response.success()
                        print(f"‚úÖ {self.user_id}: Query successful - {query[:30]}...")
                    else:
                        response.failure("Missing 'answer' field in JSON")
                except json.JSONDecodeError:
                    response.failure("Invalid JSON response")
            elif response.status_code == 503:
                # Circuit breaker OPEN - Expected behavior!
                print(f"‚ö° {self.user_id}: Circuit breaker triggered (503)")
                response.success()  # Kh√¥ng t√≠nh l√† l·ªói, l√† feature!
            else:
                response.failure(f"HTTP {response.status_code}")

    @task(3)
    def create_chat(self):
        """
        Task chat: Create new chat session (weight=3)

        M√¥ ph·ªèng user t·∫°o conversation m·ªõi!
        """
        topic = random.choice(["AI", "ML", "NLP", "RAG", "LLMs"])

        payload = {
            "title": f"Chat about {topic}",
            "metadata": {"topic": topic, "test": True},
        }

        with self.client.post(
            LoadTestConfig.CHAT_ENDPOINT,
            json=payload,
            timeout=LoadTestConfig.CHAT_TIMEOUT,
            catch_response=True,
            name="Create Chat",
        ) as response:
            if response.status_code == 201:
                try:
                    data = response.json()
                    if "chat_id" in data:
                        response.success()
                        print(f"üí¨ {self.user_id}: Chat created about {topic}")
                    else:
                        response.failure("Missing 'chat_id' field")
                except json.JSONDecodeError:
                    response.failure("Invalid JSON response")
            elif response.status_code == 503:
                print(f"‚ö° {self.user_id}: Circuit breaker triggered in chat")
                response.success()
            else:
                response.failure(f"HTTP {response.status_code}")

    @task(2)
    def check_cache_stats(self):
        """
        Task cache stats check (weight=2)

        User ho·∫∑c monitoring system check cache performance!
        """
        with self.client.get(
            LoadTestConfig.CACHE_STATS_ENDPOINT,
            timeout=LoadTestConfig.METRICS_TIMEOUT,
            catch_response=True,
            name="Cache Stats",
        ) as response:
            if response.status_code == 200:
                try:
                    data = response.json()
                    if "semantic_cache" in data:
                        response.success()
                        print(f"üìä {self.user_id}: Cache stats checked")
                    else:
                        response.failure("Missing cache stats")
                except json.JSONDecodeError:
                    response.failure("Invalid JSON response")
            else:
                response.failure(f"HTTP {response.status_code}")

    @task(1)
    def health_check(self):
        """
        Task health check (weight=1)

        Load balancer ho·∫∑c monitoring check health!
        """
        with self.client.get(
            LoadTestConfig.HEALTH_ENDPOINT, timeout=5, catch_response=True, name="Health Check"
        ) as response:
            if response.status_code == 200:
                response.success()
            else:
                response.failure(f"HTTP {response.status_code}")


# ============================================================================
# üë§ User Classes - C√°c lo·∫°i user v·ªõi behavior kh√°c nhau
# ============================================================================


class NormalUser(HttpUser):
    """
    User b√¨nh th∆∞·ªùng: Query ·ªïn ƒë·ªãnh, wait time h·ª£p l√Ω

    ƒê√¢y l√† 80% traffic th·ª±c t·∫ø - user t∆∞∆°ng t√°c t·ª± nhi√™n! üéØ
    """

    tasks = [OllamaUserBehavior]
    wait_time = between(2, 5)  # Wait 2-5s gi·ªØa c√°c request (realistic!)
    weight = 8  # 80% users l√† normal


class PowerUser(HttpUser):
    """
    Power user: Query nhi·ªÅu h∆°n, wait time ng·∫Øn h∆°n

    Developer ho·∫∑c heavy user - 15% traffic! üí™
    """

    tasks = [OllamaUserBehavior]
    wait_time = between(0.5, 2)  # Nhanh h∆°n g·∫•p 2-3 l·∫ßn
    weight = 2  # 15% users


class SpikeUser(HttpUser):
    """
    Spike user: Burst traffic ƒë·ªôt ng·ªôt, no wait time

    Simulate traffic spike - 5% users nh∆∞ng t·∫°o √°p l·ª±c l·ªõn! üî•
    """

    tasks = [OllamaUserBehavior]
    wait_time = between(0, 0.5)  # G·∫ßn nh∆∞ kh√¥ng wait
    weight = 1  # 5% users


# ============================================================================
# üé¨ Main Entry Point
# ============================================================================

if __name__ == "__main__":
    """
    Ch·∫°y local test ƒë·ªÉ verify tr∆∞·ªõc khi stress test l·ªõn!

    Usage:
        locust -f locustfile.py --host=http://localhost:8000
    """
    print(
        """
    üî• Ollama Load Test Ready!

    Commands:
        # Web UI mode (recommended):
        locust -f locustfile.py --host=http://localhost:8000

        # Headless mode (CI/CD):
        locust -f locustfile.py --host=http://localhost:8000 \\
               --users 100 --spawn-rate 10 --run-time 5m --headless

        # Distributed mode (multiple workers):
        locust -f locustfile.py --master --host=http://localhost:8000
        locust -f locustfile.py --worker --master-host=localhost

    Vibe: Testing nh∆∞ rockstar! üé∏
    """
    )
